{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate data: $Y_1 = X_1 \\cos(X_2)$, $Y_2 = X_1 \\sin(X_2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_events = 2 * 10**6 # dataset size\n",
    "feature_std = 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1, X2 = (np.random.normal(0, feature_std, (n_events, 1)), \n",
    "          np.random.uniform(-np.pi, np.pi, (n_events, 1)))\n",
    "Y1, Y2 = X1*np.cos(X2), X1*np.sin(X2)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plt.hist(X1)\n",
    "plt.xlabel(\"X1\")\n",
    "plt.title(\"X1 Distribution\")\n",
    "plt.show()\n",
    "plt.hist(X2)\n",
    "plt.xlabel(\"X2\")\n",
    "plt.title(\"X2 Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF.Keras Neural Network"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "onlyCPU = True\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "if onlyCPU:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "else:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "if tf.__version__[0] ==1:\n",
    "    gpu_options = tf.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.5)\n",
    "    sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "elif tf.__version__[0] ==2:\n",
    "    gpu_options = tf.compat.v1.GPUOptions(allow_growth=True, per_process_gpu_memory_fraction=0.5)\n",
    "    sess = tf.compat.v1.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom layer def: Dense layer with tanh bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "class CustomLayer(keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Custom Dense Layer that applies a tanh on bias\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, units=32):\n",
    "        super(CustomLayer, self).__init__()\n",
    "        self.units = units\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.w = self.add_weight(name=\"w\",\n",
    "            shape=(input_shape[-1], self.units),\n",
    "            initializer=\"random_normal\",\n",
    "            trainable=True,\n",
    "        )\n",
    "        self.b = self.add_weight(name=\"b\",\n",
    "            shape=(self.units,), initializer=\"random_normal\", trainable=True\n",
    "        )\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.w) + tf.math.tanh(self.b)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, LeakyReLU\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "n_hidden = 3\n",
    "n_nodes = 32\n",
    "\n",
    "input1 = Input(shape=(X1.shape[1],))\n",
    "input2 = Input(shape=(X2.shape[1],))\n",
    "inputs = Concatenate(axis=-1)([input1, input2])\n",
    "hidden = Dense(n_nodes, activation='relu')(inputs)\n",
    "\n",
    "for i in range(n_hidden -1):\n",
    "    hidden = CustomLayer(n_nodes)(hidden) \n",
    "    hidden = LeakyReLU()(hidden)\n",
    "predictionY1 = Dense(1, activation='linear')(hidden)\n",
    "predictionY2 = Dense(1, activation='linear')(hidden)\n",
    "\n",
    "nn_model = Model(inputs=[input1, input2], outputs=[predictionY1, predictionY2])\n",
    "nn_model.compile(optimizer='adam',\n",
    "              loss='mean_squared_error',)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_4 (InputLayer)            [(None, 1)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2)            0           input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 32)           96          concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "custom_layer_2 (CustomLayer)    (None, 32)           1056        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 32)           0           custom_layer_2[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "custom_layer_3 (CustomLayer)    (None, 32)           1056        leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 32)           0           custom_layer_3[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            33          leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 1)            33          leaky_re_lu_3[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 2,274\n",
      "Trainable params: 2,274\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1954/1954 [==============================] - 6s 3ms/step - loss: 0.0203 - dense_4_loss: 0.0111 - dense_5_loss: 0.0093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f73e86f9a90>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn_model.fit(x=[X1, X2], y=[Y1, Y2], epochs=1, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y1_pred, Y2_pred = nn_model.predict([X1, X2], batch_size=1024*4)\n",
    "Y1_pred, Y2_pred = Y1_pred.ravel(), Y2_pred.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.000318922683635748, 0.0006225795475563963)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_pred=Y1_pred, y_true=Y1), mean_squared_error(y_pred=Y2_pred, y_true=Y2),"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save NN model\n",
    "## Note: not in HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: nn_model/assets\n"
     ]
    }
   ],
   "source": [
    "nn_model.save(\"nn_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to onnx format\n",
    "## Note: use tf2onnx not keras2onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-17 13:17:34.148139: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:34.148185: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "/home/aishik/.conda/envs/onnx/lib/python3.9/runpy.py:127: RuntimeWarning: 'tf2onnx.convert' found in sys.modules after import of package 'tf2onnx', but prior to execution of 'tf2onnx.convert'; this may result in unpredictable behaviour\n",
      "  warn(RuntimeWarning(msg))\n",
      "2022-03-17 13:17:35.999373: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2022-03-17 13:17:36.024846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-17 13:17:36.025013: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:36.025154: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublas.so.11'; dlerror: libcublas.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:36.025304: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcublasLt.so.11'; dlerror: libcublasLt.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:36.025410: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcufft.so.10'; dlerror: libcufft.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:36.025507: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcurand.so.10'; dlerror: libcurand.so.10: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:36.025602: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusolver.so.11'; dlerror: libcusolver.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:36.025695: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcusparse.so.11'; dlerror: libcusparse.so.11: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:36.025793: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudnn.so.8'; dlerror: libcudnn.so.8: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/lib::/usr/local/cuda/lib64\n",
      "2022-03-17 13:17:36.025815: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-17 13:17:36.026237: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-03-17 13:17:36.027678: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-17 13:17:36.027716: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "2022-03-17 13:17:36,029 - WARNING - '--tag' not specified for saved_model. Using --tag serve\n",
      "2022-03-17 13:17:36,485 - INFO - Signatures found in model: [serving_default].\n",
      "2022-03-17 13:17:36,486 - WARNING - '--signature_def' not specified, using first signature: serving_default\n",
      "2022-03-17 13:17:36,486 - INFO - Output names: ['dense_4', 'dense_5']\n",
      "2022-03-17 13:17:36.489956: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-03-17 13:17:36.490117: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-03-17 13:17:36.491696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-17 13:17:36.491732: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-17 13:17:36.671309: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-17 13:17:36.671352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-03-17 13:17:36.671366: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-03-17 13:17:36.692307: I tensorflow/core/platform/profile_utils/cpu_utils.cc:114] CPU Frequency: 2098710000 Hz\n",
      "2022-03-17 13:17:36.698577: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  function_optimizer: Graph size after: 58 nodes (43), 88 edges (72), time = 3.252ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.1ms.\n",
      "\n",
      "2022-03-17 13:17:36.787878: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-17 13:17:36.787918: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      \n",
      "WARNING:tensorflow:From /home/aishik/.conda/envs/onnx/lib/python3.9/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-03-17 13:17:36,803 - WARNING - From /home/aishik/.conda/envs/onnx/lib/python3.9/site-packages/tf2onnx/tf_loader.py:603: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.compat.v1.graph_util.extract_sub_graph`\n",
      "2022-03-17 13:17:36.809532: I tensorflow/core/grappler/devices.cc:69] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 1\n",
      "2022-03-17 13:17:36.809704: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2022-03-17 13:17:36.811769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:05:00.0 name: GeForce GTX 1080 Ti computeCapability: 6.1\n",
      "coreClock: 1.582GHz coreCount: 28 deviceMemorySize: 10.91GiB deviceMemoryBandwidth: 451.17GiB/s\n",
      "2022-03-17 13:17:36.811802: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1766] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "2022-03-17 13:17:36.811827: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-03-17 13:17:36.811840: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2022-03-17 13:17:36.811854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2022-03-17 13:17:36.822222: I tensorflow/core/grappler/optimizers/meta_optimizer.cc:1144] Optimization results for grappler item: graph_to_optimize\n",
      "  constant_folding: Graph size after: 38 nodes (-20), 66 edges (-22), time = 4.594ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.052ms.\n",
      "  constant_folding: Graph size after: 38 nodes (0), 66 edges (0), time = 1.415ms.\n",
      "  function_optimizer: function_optimizer did nothing. time = 0.076ms.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-03-17 13:17:36,843 - INFO - Using tensorflow=2.5.0, onnx=1.9.0, tf2onnx=1.8.5/50049d\n",
      "2022-03-17 13:17:36,843 - INFO - Using opset <onnx, 9>\n",
      "2022-03-17 13:17:36,848 - INFO - Computed 0 values for constant folding\n",
      "2022-03-17 13:17:36,902 - INFO - Optimizing ONNX model\n",
      "2022-03-17 13:17:36,993 - INFO - After optimization: Const -1 (11->10), Identity -10 (10->0)\n",
      "2022-03-17 13:17:36,996 - INFO - \n",
      "2022-03-17 13:17:36,996 - INFO - Successfully converted TensorFlow model nn_model/ to ONNX\n",
      "2022-03-17 13:17:36,996 - INFO - Model inputs: ['input_3:0', 'input_4:0']\n",
      "2022-03-17 13:17:36,996 - INFO - Model outputs: ['dense_4', 'dense_5']\n",
      "2022-03-17 13:17:36,996 - INFO - ONNX model is saved at nn_model.onnx\n"
     ]
    }
   ],
   "source": [
    "!python -m tf2onnx.convert --saved-model nn_model/ --output nn_model.onnx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model in ONNX RT for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "sess = onnxruntime.InferenceSession(\"nn_model.onnx\",)\n",
    "input_names = sess.get_inputs()\n",
    "\n",
    "def pred_ONNX(X):\n",
    "    #\n",
    "    # Mimic any training pre-preocessing here\n",
    "    #\n",
    "    \n",
    "    data = [x.astype(np.float32) for x in X]\n",
    "    feed = zip(sorted(i_.name for i_ in input_names), data)\n",
    "    pred = sess.run(None, dict(feed))\n",
    "    return pred\n",
    "\n",
    "\n",
    "# could turn off multi-threading etc\n",
    "#sess_options = onnxruntime.SessionOptions()\n",
    "#sess = onnxruntime.InferenceSession(\"nn_model.onnx\", sess_options)\n",
    "# sess_options.inter_op_num_threads = 1\n",
    "# sess_options.intra_op_num_threads = 1\n",
    "# sess_options.execution_mode = rt.ExecutionMode.ORT_SEQUENTIAL\n",
    "# sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_ALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similar functions for Keras model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "nn_model = load_model(\"nn_model\")\n",
    "def pred_Keras(X):\n",
    "    #\n",
    "    # Mimic any training pre-preocessing here\n",
    "    #\n",
    "    \n",
    "    return nn_model.predict(X, batch_size=1024)\n",
    "\n",
    "def pred_KerasNoTrain(X):\n",
    "    #\n",
    "    # Mimic any training pre-preocessing here\n",
    "    #\n",
    "    \n",
    "    return nn_model(X, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict and compare ORT to Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04793903],\n",
       "       [-0.29843515],\n",
       "       [-0.27908307],\n",
       "       [ 0.02063516],\n",
       "       [ 0.03614256]], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1_pred_k, y2_pred_k = pred_Keras([X1, X2])\n",
    "y1_pred_k[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.04793907],\n",
       "       [-0.29843518],\n",
       "       [-0.279083  ],\n",
       "       [ 0.02063511],\n",
       "       [ 0.03614252]], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X is expected to be a list of inputs, if only one, pass [X]\n",
    "y1_pred_o, y2_pred_o = pred_ONNX([X1, X2])\n",
    "y1_pred_o[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORT & Keras values same for all Y1:  True \n",
      "ORT & Keras values same for all Y2:  True\n"
     ]
    }
   ],
   "source": [
    "print (\"ORT & Keras values same for all Y1: \", np.isclose(y1_pred_k, y1_pred_o, atol=1e-05).all(), \n",
    " \"\\nORT & Keras values same for all Y2: \", np.isclose(y2_pred_k, y2_pred_o, atol=1e-05).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE for Keras:  0.000318922683635748 0.0006225795475563963\n",
      "MSE for ORT:  0.0003189226812967008 0.0006225795522400696\n"
     ]
    }
   ],
   "source": [
    "print (\"MSE for Keras: \",\n",
    "       mean_squared_error( y_pred=y1_pred_k, y_true=Y1), \n",
    "       mean_squared_error(y_pred=y2_pred_k, y_true=Y2),)\n",
    "print (\"MSE for ORT: \", \n",
    "       mean_squared_error(y_pred=y1_pred_o, y_true=Y1), \n",
    "       mean_squared_error(y_pred=y2_pred_o, y_true=Y2),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timing comparisons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53 s, sys: 3.47 s, total: 56.5 s\n",
      "Wall time: 43.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(l):\n",
    "    _ = pred_Keras([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.8 s, sys: 277 ms, total: 30 s\n",
      "Wall time: 4.81 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(l):\n",
    "    __ = pred_ONNX([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.5 s, sys: 15.8 s, total: 42.3 s\n",
      "Wall time: 6.78 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(l):\n",
    "    _ = pred_KerasNoTrain([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.58 s, sys: 271 ms, total: 4.85 s\n",
      "Wall time: 10.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = pred_Keras([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.19 s, sys: 7.12 ms, total: 2.2 s\n",
      "Wall time: 1.01 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "__ = pred_ONNX([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.42 s, sys: 1.06 s, total: 2.48 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "_ = pred_KerasNoTrain([X1, X2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
